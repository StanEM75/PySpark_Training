{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c6bb73",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56089d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spark\n",
    "from pyspark.sql import SparkSession, functions as F, types as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722aff6f",
   "metadata": {},
   "source": [
    "## Instantiate a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0e59a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session\n",
    "spark = (SparkSession.builder\n",
    "         # Give a name to the Spark application\n",
    "         .appName(\"spark-fundamentals-lab\")\n",
    "         # Execute the Spark using the resources of the local device\n",
    "         .master(\"local[*]\")\n",
    "         # Activate AQE to optimize shuffle and join strategy\n",
    "         .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "         # Looks for another Spark session to activate it, or create one if needed\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4eca4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.0.0\n"
     ]
    }
   ],
   "source": [
    "# Print the Spark version\n",
    "print(\"Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41a9b90",
   "metadata": {},
   "source": [
    "## Load the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1868278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a plan to load the csv, in multiple steps (nothing is loaded until an action is performed)\n",
    "df = (\n",
    "    spark.read\n",
    "    # Set the first rows as headers\n",
    "    .option(\"header\", True)\n",
    "    # Deduct data types\n",
    "    .option(\"inferSchema\", True)\n",
    "    # Import the csv \n",
    "    .csv(\"data/airlines_flights_data.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24d96bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight: string (nullable = true)\n",
      " |-- source_city: string (nullable = true)\n",
      " |-- departure_time: string (nullable = true)\n",
      " |-- stops: string (nullable = true)\n",
      " |-- arrival_time: string (nullable = true)\n",
      " |-- destination_city: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- days_left: integer (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d866077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|index|airline |flight |source_city|departure_time|stops|arrival_time |destination_city|class  |duration|days_left|price|\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|0    |SpiceJet|SG-8709|Delhi      |Evening       |zero |Night        |Mumbai          |Economy|2.17    |1        |5953 |\n",
      "|1    |SpiceJet|SG-8157|Delhi      |Early_Morning |zero |Morning      |Mumbai          |Economy|2.33    |1        |5953 |\n",
      "|2    |AirAsia |I5-764 |Delhi      |Early_Morning |zero |Early_Morning|Mumbai          |Economy|2.17    |1        |5956 |\n",
      "|3    |Vistara |UK-995 |Delhi      |Morning       |zero |Afternoon    |Mumbai          |Economy|2.25    |1        |5955 |\n",
      "|4    |Vistara |UK-963 |Delhi      |Morning       |zero |Morning      |Mumbai          |Economy|2.33    |1        |5955 |\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Execute an action to load the data: load the 5 first rows of the dataframe\n",
    "df.show(5, truncate=False) # truncate=False is to be sure we print the entire content of a cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15965d3",
   "metadata": {},
   "source": [
    "## Write the dataframe in Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a0126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write in Parquet\n",
    "(\n",
    "    df.write\n",
    "      # Removes and entirely reloads data\n",
    "      .mode(\"overwrite\")\n",
    "      # Convert the dataframe to Parquet and export it to the data folder\n",
    "      .parquet(\"data/silver/airlines_flights_data\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1675b6c",
   "metadata": {},
   "source": [
    "## Reload the data in Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6db1d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = spark.read.parquet(\"data/silver/airlines_flights_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d678a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight: string (nullable = true)\n",
      " |-- source_city: string (nullable = true)\n",
      " |-- departure_time: string (nullable = true)\n",
      " |-- stops: string (nullable = true)\n",
      " |-- arrival_time: string (nullable = true)\n",
      " |-- destination_city: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- days_left: integer (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema (columns and their respective types)\n",
    "dfp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a5904f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300153"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows in the dataframe (equivalent of len in pandas)\n",
    "dfp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20152ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/04 20:35:32 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 11:>                                                         (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------+--------------------+-----------+--------------+------+------------+----------------+--------+------------------+------------------+------------------+\n",
      "|summary|            index|airline|              flight|source_city|departure_time| stops|arrival_time|destination_city|   class|          duration|         days_left|             price|\n",
      "+-------+-----------------+-------+--------------------+-----------+--------------+------+------------+----------------+--------+------------------+------------------+------------------+\n",
      "|  count|           300153| 300153|              300153|     300153|        300153|300153|      300153|          300153|  300153|            300153|            300153|            300153|\n",
      "|   mean|         150076.0|   NULL|5.427411873908628...|       NULL|          NULL|  NULL|        NULL|            NULL|    NULL|12.221020812718939|26.004750910369044|20889.660523133203|\n",
      "| stddev|86646.85201148395|   NULL|1.803651814074487...|       NULL|          NULL|  NULL|        NULL|            NULL|    NULL| 7.191997238119021|13.561003687093562|22697.767366074488|\n",
      "|    min|                0|AirAsia|            0.00E+00|  Bangalore|     Afternoon|   one|   Afternoon|       Bangalore|Business|              0.83|                 1|              1105|\n",
      "|    25%|            75014|   NULL|                 0.0|       NULL|          NULL|  NULL|        NULL|            NULL|    NULL|              6.83|                15|              4783|\n",
      "|    50%|           150072|   NULL|                 0.0|       NULL|          NULL|  NULL|        NULL|            NULL|    NULL|             11.25|                26|              7425|\n",
      "|    75%|           225127|   NULL|                 0.0|       NULL|          NULL|  NULL|        NULL|            NULL|    NULL|             16.17|                38|             42521|\n",
      "|    max|           300152|Vistara|              UK-996|     Mumbai|         Night|  zero|       Night|          Mumbai| Economy|             49.83|                49|            123071|\n",
      "+-------+-----------------+-------+--------------------+-----------+--------------+------+------------+----------------+--------+------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print the main statistics on the dataframe (equivalent of describe in pandas)\n",
    "dfp.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087b86e",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "329b9e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|index|airline |flight |source_city|departure_time|stops|arrival_time |destination_city|class  |duration|days_left|price|\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|0    |SpiceJet|SG-8709|Delhi      |Evening       |zero |Night        |Mumbai          |Economy|2.17    |1        |5953 |\n",
      "|1    |SpiceJet|SG-8157|Delhi      |Early_Morning |zero |Morning      |Mumbai          |Economy|2.33    |1        |5953 |\n",
      "|2    |AirAsia |I5-764 |Delhi      |Early_Morning |zero |Early_Morning|Mumbai          |Economy|2.17    |1        |5956 |\n",
      "|3    |Vistara |UK-995 |Delhi      |Morning       |zero |Afternoon    |Mumbai          |Economy|2.25    |1        |5955 |\n",
      "|4    |Vistara |UK-963 |Delhi      |Morning       |zero |Morning      |Mumbai          |Economy|2.33    |1        |5955 |\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "dfp.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9e05d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------+-----------+--------------+-----+------------+----------------+-------+--------+---------+-----+\n",
      "|index|airline |flight |source_city|departure_time|stops|arrival_time|destination_city|class  |duration|days_left|price|\n",
      "+-----+--------+-------+-----------+--------------+-----+------------+----------------+-------+--------+---------+-----+\n",
      "|0    |SpiceJet|SG-8709|Delhi      |Evening       |zero |Night       |Mumbai          |Economy|2.17    |1        |5953 |\n",
      "|1    |SpiceJet|SG-8157|Delhi      |Early_Morning |zero |Morning     |Mumbai          |Economy|2.33    |1        |5953 |\n",
      "|28   |SpiceJet|SG-8169|Delhi      |Evening       |zero |Night       |Mumbai          |Economy|2.33    |1        |10260|\n",
      "|38   |SpiceJet|SG-2976|Delhi      |Evening       |one  |Night       |Mumbai          |Economy|4.5     |1        |12123|\n",
      "|39   |SpiceJet|SG-2976|Delhi      |Evening       |one  |Morning     |Mumbai          |Economy|15.25   |1        |12123|\n",
      "+-----+--------+-------+-----------+--------------+-----+------------+----------------+-------+--------+---------+-----+\n",
      "only showing top 5 rows\n",
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(airline#170) AND (airline#170 = SpiceJet))\n",
      "+- *(1) ColumnarToRow\n",
      "   +- FileScan parquet [index#169,airline#170,flight#171,source_city#172,departure_time#173,stops#174,arrival_time#175,destination_city#176,class#177,duration#178,days_left#179,price#180] Batched: true, DataFilters: [isnotnull(airline#170), (airline#170 = SpiceJet)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/stanislas/Projets/Formation/spark_training/data/silver/air..., PartitionFilters: [], PushedFilters: [IsNotNull(airline), EqualTo(airline,SpiceJet)], ReadSchema: struct<index:int,airline:string,flight:string,source_city:string,departure_time:string,stops:stri...\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9011"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter is a transformation --> By executing only this command, we only get a plan\n",
    "dfp.filter(\"airline=='SpiceJet'\")\n",
    "\n",
    "# By adding the action show, we can execute a query and print a result dataframe\n",
    "dfp.filter(\"airline=='SpiceJet'\").show(5, truncate=False)\n",
    "\n",
    "# Explain the execution plan of the query\n",
    "dfp.filter(\"airline=='SpiceJet'\").explain()\n",
    "\n",
    "# Print the number of rows matching with the condition\n",
    "dfp.filter(\"airline=='SpiceJet'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b4a422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-training (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
