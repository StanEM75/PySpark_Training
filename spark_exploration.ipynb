{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6c6bb73",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56089d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spark\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, functions as F, types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee3ad62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/07 09:05:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722aff6f",
   "metadata": {},
   "source": [
    "## Instantiate a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e59a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/07 09:05:49 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = (SparkSession.builder\n",
    "         # Give a name to the Spark application\n",
    "         .appName(\"spark-fundamentals-lab\")\n",
    "         # Execute the Spark using the resources of the local device\n",
    "         .master(\"local[*]\")\n",
    "         # Activate AQE to optimize shuffle and join strategy\n",
    "         .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "         # Looks for another Spark session to activate it, or create one if needed\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4eca4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 4.0.0\n"
     ]
    }
   ],
   "source": [
    "# Print the Spark version\n",
    "print(\"Spark version:\", spark.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeee80ba",
   "metadata": {},
   "source": [
    "## Load the dataframe and write it in Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41a9b90",
   "metadata": {},
   "source": [
    "### Load the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1868278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a plan to load the csv, in multiple steps (nothing is loaded until an action is performed)\n",
    "df = (\n",
    "    spark.read\n",
    "    # Set the first rows as headers\n",
    "    .option(\"header\", True)\n",
    "    # Deduct data types\n",
    "    .option(\"inferSchema\", True)\n",
    "    # Import the csv \n",
    "    .csv(\"data/airlines_flights_data.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24d96bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight: string (nullable = true)\n",
      " |-- source_city: string (nullable = true)\n",
      " |-- departure_time: string (nullable = true)\n",
      " |-- stops: string (nullable = true)\n",
      " |-- arrival_time: string (nullable = true)\n",
      " |-- destination_city: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- days_left: integer (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d866077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|index|airline |flight |source_city|departure_time|stops|arrival_time |destination_city|class  |duration|days_left|price|\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|0    |SpiceJet|SG-8709|Delhi      |Evening       |zero |Night        |Mumbai          |Economy|2.17    |1        |5953 |\n",
      "|1    |SpiceJet|SG-8157|Delhi      |Early_Morning |zero |Morning      |Mumbai          |Economy|2.33    |1        |5953 |\n",
      "|2    |AirAsia |I5-764 |Delhi      |Early_Morning |zero |Early_Morning|Mumbai          |Economy|2.17    |1        |5956 |\n",
      "|3    |Vistara |UK-995 |Delhi      |Morning       |zero |Afternoon    |Mumbai          |Economy|2.25    |1        |5955 |\n",
      "|4    |Vistara |UK-963 |Delhi      |Morning       |zero |Morning      |Mumbai          |Economy|2.33    |1        |5955 |\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Execute an action to load the data: load the 5 first rows of the dataframe\n",
    "df.show(5, truncate=False) # truncate=False is to be sure we print the entire content of a cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15965d3",
   "metadata": {},
   "source": [
    "### Write the dataframe in Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "689a0126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write in Parquet\n",
    "(\n",
    "    df.write\n",
    "      # Removes and entirely reloads data\n",
    "      .mode(\"overwrite\")\n",
    "      # Convert the dataframe to Parquet and export it to the data folder\n",
    "      .parquet(\"data/silver/airlines_flights_data\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1675b6c",
   "metadata": {},
   "source": [
    "### Reload the data in Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6db1d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = spark.read.parquet(\"data/silver/airlines_flights_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d678a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- flight: string (nullable = true)\n",
      " |-- source_city: string (nullable = true)\n",
      " |-- departure_time: string (nullable = true)\n",
      " |-- stops: string (nullable = true)\n",
      " |-- arrival_time: string (nullable = true)\n",
      " |-- destination_city: string (nullable = true)\n",
      " |-- class: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- days_left: integer (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema (columns and their respective types)\n",
    "dfp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73a5904f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300153"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows in the dataframe (equivalent of len in pandas)\n",
    "dfp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f20152ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/07 09:05:52 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 8:=========>                                                 (1 + 5) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------+--------------------+-----------+--------------+------+------------+----------------+--------+------------------+------------------+------------------+\n",
      "|summary|            index|airline|              flight|source_city|departure_time| stops|arrival_time|destination_city|   class|          duration|         days_left|             price|\n",
      "+-------+-----------------+-------+--------------------+-----------+--------------+------+------------+----------------+--------+------------------+------------------+------------------+\n",
      "|  count|           300153| 300153|              300153|     300153|        300153|300153|      300153|          300153|  300153|            300153|            300153|            300153|\n",
      "|   mean|         150076.0|   NULL|5.427411873908628...|       NULL|          NULL|  NULL|        NULL|            NULL|    NULL|12.221020812718939|26.004750910369044|20889.660523133203|\n",
      "| stddev|86646.85201148395|   NULL|1.803651814074487...|       NULL|          NULL|  NULL|        NULL|            NULL|    NULL| 7.191997238119021|13.561003687093562|22697.767366074488|\n",
      "|    min|                0|AirAsia|            0.00E+00|  Bangalore|     Afternoon|   one|   Afternoon|       Bangalore|Business|              0.83|                 1|              1105|\n",
      "|    25%|            75014|   NULL|                 0.0|       NULL|          NULL|  NULL|        NULL|            NULL|    NULL|              6.83|                15|              4783|\n",
      "|    50%|           150072|   NULL|                 0.0|       NULL|          NULL|  NULL|        NULL|            NULL|    NULL|             11.25|                26|              7425|\n",
      "|    75%|           225127|   NULL|                 0.0|       NULL|          NULL|  NULL|        NULL|            NULL|    NULL|             16.17|                38|             42521|\n",
      "|    max|           300152|Vistara|              UK-996|     Mumbai|         Night|  zero|       Night|          Mumbai| Economy|             49.83|                49|            123071|\n",
      "+-------+-----------------+-------+--------------------+-----------+--------------+------+------------+----------------+--------+------------------+------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Print the main statistics on the dataframe (equivalent of describe in pandas)\n",
    "dfp.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c087b86e",
   "metadata": {},
   "source": [
    "## Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235fe8d",
   "metadata": {},
   "source": [
    "### First rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329b9e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|index|airline |flight |source_city|departure_time|stops|arrival_time |destination_city|class  |duration|days_left|price|\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|0    |SpiceJet|SG-8709|Delhi      |Evening       |zero |Night        |Mumbai          |Economy|2.17    |1        |5953 |\n",
      "|1    |SpiceJet|SG-8157|Delhi      |Early_Morning |zero |Morning      |Mumbai          |Economy|2.33    |1        |5953 |\n",
      "|2    |AirAsia |I5-764 |Delhi      |Early_Morning |zero |Early_Morning|Mumbai          |Economy|2.17    |1        |5956 |\n",
      "|3    |Vistara |UK-995 |Delhi      |Morning       |zero |Afternoon    |Mumbai          |Economy|2.25    |1        |5955 |\n",
      "|4    |Vistara |UK-963 |Delhi      |Morning       |zero |Morning      |Mumbai          |Economy|2.33    |1        |5955 |\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "dfp.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6132e7c",
   "metadata": {},
   "source": [
    "### Filtered rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9e05d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------+-----------+--------------+-----+------------+----------------+-------+--------+---------+-----+\n",
      "|index|airline |flight |source_city|departure_time|stops|arrival_time|destination_city|class  |duration|days_left|price|\n",
      "+-----+--------+-------+-----------+--------------+-----+------------+----------------+-------+--------+---------+-----+\n",
      "|0    |SpiceJet|SG-8709|Delhi      |Evening       |zero |Night       |Mumbai          |Economy|2.17    |1        |5953 |\n",
      "|1    |SpiceJet|SG-8157|Delhi      |Early_Morning |zero |Morning     |Mumbai          |Economy|2.33    |1        |5953 |\n",
      "|28   |SpiceJet|SG-8169|Delhi      |Evening       |zero |Night       |Mumbai          |Economy|2.33    |1        |10260|\n",
      "|38   |SpiceJet|SG-2976|Delhi      |Evening       |one  |Night       |Mumbai          |Economy|4.5     |1        |12123|\n",
      "|39   |SpiceJet|SG-2976|Delhi      |Evening       |one  |Morning     |Mumbai          |Economy|15.25   |1        |12123|\n",
      "+-----+--------+-------+-----------+--------------+-----+------------+----------------+-------+--------+---------+-----+\n",
      "only showing top 5 rows\n",
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(airline#92) AND (airline#92 = SpiceJet))\n",
      "+- *(1) ColumnarToRow\n",
      "   +- FileScan parquet [index#91,airline#92,flight#93,source_city#94,departure_time#95,stops#96,arrival_time#97,destination_city#98,class#99,duration#100,days_left#101,price#102] Batched: true, DataFilters: [isnotnull(airline#92), (airline#92 = SpiceJet)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/Users/stanislas/Projets/Formation/spark_training/data/silver/air..., PartitionFilters: [], PushedFilters: [IsNotNull(airline), EqualTo(airline,SpiceJet)], ReadSchema: struct<index:int,airline:string,flight:string,source_city:string,departure_time:string,stops:stri...\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9011"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter is a transformation --> By executing only this command, we only get a plan\n",
    "dfp.filter(\"airline=='SpiceJet'\")\n",
    "\n",
    "# By adding the action show, we can execute a query and print a result dataframe\n",
    "dfp.filter(\"airline=='SpiceJet'\").show(5, truncate=False)\n",
    "\n",
    "# Explain the execution plan of the query\n",
    "dfp.filter(\"airline=='SpiceJet'\").explain()\n",
    "\n",
    "# Print the number of rows matching with the condition\n",
    "dfp.filter(\"airline=='SpiceJet'\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b4a422",
   "metadata": {},
   "source": [
    "### Query the data using SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7af25859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|index| airline| flight|source_city|departure_time|stops| arrival_time|destination_city|  class|duration|days_left|price|\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "|    0|SpiceJet|SG-8709|      Delhi|       Evening| zero|        Night|          Mumbai|Economy|    2.17|        1| 5953|\n",
      "|    1|SpiceJet|SG-8157|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5953|\n",
      "|    2| AirAsia| I5-764|      Delhi| Early_Morning| zero|Early_Morning|          Mumbai|Economy|    2.17|        1| 5956|\n",
      "|    3| Vistara| UK-995|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.25|        1| 5955|\n",
      "|    4| Vistara| UK-963|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.33|        1| 5955|\n",
      "|    5| Vistara| UK-945|      Delhi|       Morning| zero|    Afternoon|          Mumbai|Economy|    2.33|        1| 5955|\n",
      "|    6| Vistara| UK-927|      Delhi|       Morning| zero|      Morning|          Mumbai|Economy|    2.08|        1| 6060|\n",
      "|    7| Vistara| UK-951|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.17|        1| 6060|\n",
      "|    8|GO_FIRST| G8-334|      Delhi| Early_Morning| zero|      Morning|          Mumbai|Economy|    2.17|        1| 5954|\n",
      "|    9|GO_FIRST| G8-336|      Delhi|     Afternoon| zero|      Evening|          Mumbai|Economy|    2.25|        1| 5954|\n",
      "+-----+--------+-------+-----------+--------------+-----+-------------+----------------+-------+--------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary view\n",
    "df.createOrReplaceTempView(\"flights\")\n",
    "\n",
    "# Query this temporary view by using SQL\n",
    "spark.sql(\n",
    "    \"SELECT * FROM flights LIMIT 10\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e105c0a",
   "metadata": {},
   "source": [
    "### Partition the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd0796d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-------+-----------+--------------+-----+------------+----------------+-------+--------+---------+-----+\n",
      "|index|  airline| flight|source_city|departure_time|stops|arrival_time|destination_city|  class|duration|days_left|price|\n",
      "+-----+---------+-------+-----------+--------------+-----+------------+----------------+-------+--------+---------+-----+\n",
      "|84065|  AirAsia| I5-996|  Bangalore|       Evening| zero|       Night|           Delhi|Economy|    2.83|        1| 7489|\n",
      "|84066|  Vistara| UK-820|  Bangalore|       Evening| zero|       Night|           Delhi|Economy|    2.67|        1| 7489|\n",
      "|84067|  Vistara| UK-802|  Bangalore|       Evening| zero|       Night|           Delhi|Economy|    2.75|        1| 7489|\n",
      "|84068|   Indigo|6E-6139|  Bangalore|     Afternoon| zero|     Evening|           Delhi|Economy|    2.75|        1| 7488|\n",
      "|84069|   Indigo|6E-2514|  Bangalore|       Evening| zero|     Evening|           Delhi|Economy|    2.83|        1| 7488|\n",
      "|84070|   Indigo|6E-2027|  Bangalore|       Morning| zero|   Afternoon|           Delhi|Economy|    2.92|        1| 7488|\n",
      "|84071|   Indigo|6E-2174|  Bangalore|       Evening| zero|       Night|           Delhi|Economy|    2.92|        1| 7488|\n",
      "|84072|   Indigo|6E-2034|  Bangalore|       Evening| zero|       Night|           Delhi|Economy|    2.92|        1| 7488|\n",
      "|84073|Air_India| AI-505|  Bangalore|       Morning| zero|   Afternoon|           Delhi|Economy|    2.58|        1| 7489|\n",
      "|84074|Air_India| AI-501|  Bangalore|     Afternoon| zero|   Afternoon|           Delhi|Economy|    2.58|        1| 7489|\n",
      "|84075|Air_India| AI-503|  Bangalore|       Evening| zero|       Night|           Delhi|Economy|    2.75|        1| 7489|\n",
      "|84076|  AirAsia|I5-1566|  Bangalore|     Afternoon|  one|     Evening|           Delhi|Economy|    5.83|        1| 7484|\n",
      "|84077| GO_FIRST| G8-405|  Bangalore|     Afternoon|  one|     Evening|           Delhi|Economy|    4.25|        1| 7487|\n",
      "|84078| GO_FIRST| G8-873|  Bangalore|       Morning|  one|       Night|           Delhi|Economy|    11.5|        1| 7487|\n",
      "|84079| GO_FIRST| G8-385|  Bangalore| Early_Morning|  one|       Night|           Delhi|Economy|    14.0|        1| 7487|\n",
      "|84080| SpiceJet| SG-136|  Bangalore| Early_Morning| zero|     Morning|           Delhi|Economy|    2.75|        1| 7593|\n",
      "|84081|  AirAsia|I5-1528|  Bangalore| Early_Morning| zero|     Morning|           Delhi|Economy|    2.75|        1| 7905|\n",
      "|84082|   Indigo|6E-2186|  Bangalore| Early_Morning| zero|     Morning|           Delhi|Economy|     3.0|        1| 7908|\n",
      "|84083|Air_India| AI-804|  Bangalore| Early_Morning| zero|     Morning|           Delhi|Economy|    2.75|        1| 7909|\n",
      "|84084|  Vistara| UK-810|  Bangalore| Early_Morning| zero|     Morning|           Delhi|Economy|    2.67|        1| 8329|\n",
      "+-----+---------+-------+-----------+--------------+-----+------------+----------------+-------+--------+---------+-----+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df.repartition(10, \"source_city\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66b62c",
   "metadata": {},
   "source": [
    "## Basic analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16553dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(source_city='Chennai', destination_city='Bangalore', average_price=25081.85045433544), Row(source_city='Kolkata', destination_city='Chennai', average_price=23660.36104013227), Row(source_city='Bangalore', destination_city='Kolkata', average_price=23500.061228560033), Row(source_city='Bangalore', destination_city='Chennai', average_price=23321.85007800312), Row(source_city='Mumbai', destination_city='Bangalore', average_price=23147.87380675204), Row(source_city='Bangalore', destination_city='Mumbai', average_price=23128.618672231238), Row(source_city='Mumbai', destination_city='Chennai', average_price=22781.89911154985), Row(source_city='Chennai', destination_city='Mumbai', average_price=22765.849646605267), Row(source_city='Kolkata', destination_city='Bangalore', average_price=22744.80842833876), Row(source_city='Chennai', destination_city='Kolkata', average_price=22669.93240727481), Row(source_city='Mumbai', destination_city='Kolkata', average_price=22379.146722742422), Row(source_city='Kolkata', destination_city='Mumbai', average_price=22078.883578965728), Row(source_city='Hyderabad', destination_city='Chennai', average_price=21848.06598905395), Row(source_city='Chennai', destination_city='Hyderabad', average_price=21591.345403899722), Row(source_city='Kolkata', destination_city='Hyderabad', average_price=21500.011396732938), Row(source_city='Hyderabad', destination_city='Bangalore', average_price=21347.177998472118), Row(source_city='Bangalore', destination_city='Hyderabad', average_price=21226.121191756272), Row(source_city='Mumbai', destination_city='Hyderabad', average_price=21004.04670487106), Row(source_city='Hyderabad', destination_city='Kolkata', average_price=20823.89320145236), Row(source_city='Delhi', destination_city='Kolkata', average_price=20566.409418468244), Row(source_city='Hyderabad', destination_city='Mumbai', average_price=20080.865759141496), Row(source_city='Kolkata', destination_city='Delhi', average_price=19422.35455929945), Row(source_city='Delhi', destination_city='Chennai', average_price=19369.881354359924), Row(source_city='Delhi', destination_city='Mumbai', average_price=19355.82981228334), Row(source_city='Chennai', destination_city='Delhi', average_price=18981.863947664315), Row(source_city='Mumbai', destination_city='Delhi', average_price=18725.32000810318), Row(source_city='Delhi', destination_city='Bangalore', average_price=17880.216314587495), Row(source_city='Bangalore', destination_city='Delhi', average_price=17723.313972084907), Row(source_city='Delhi', destination_city='Hyderabad', average_price=17347.288379073758), Row(source_city='Hyderabad', destination_city='Delhi', average_price=17243.945685398543)]\n",
      "The most expensive flight seems to be the one between Chennai and Bangalore, with a price of 25082\n",
      "WARNING: Data is not processed yet, so this is just an assumption that needs to be checked\n"
     ]
    }
   ],
   "source": [
    "# Print the trip with the highest average price\n",
    "# Initiate a SQL query in a string variable\n",
    "sql_query_1 = \"SELECT \" \\\n",
    "\"                   source_city, \" \\\n",
    "\"                   destination_city, \" \\\n",
    "\"                   AVG(price) AS average_price \" \\\n",
    "\"            FROM \" \\\n",
    "\"                   flights \" \\\n",
    "\"            GROUP BY \" \\\n",
    "\"                   source_city, \" \\\n",
    "\"                   destination_city \" \\\n",
    "\"            ORDER BY \" \\\n",
    "\"                   average_price DESC\"\n",
    "\n",
    "# Execute the query using Spark SQL and put into a list\n",
    "output_1 = spark.sql(\n",
    "    sql_query_1\n",
    ").collect() \n",
    "\n",
    "print(output_1)\n",
    "\n",
    "# The most expensive flight seems to be the one between Chennai and Bangalore\n",
    "# WARNING: Data is not processed yet, so this is just an assumption that needs to be checked\n",
    "\n",
    "print(f\"The most expensive flight seems to be the one between {output_1[0][0]} and {output_1[0][1]}, with a price of {round(output_1[0][2])}\")\n",
    "\n",
    "print(\"WARNING: Data is not processed yet, so this is just an assumption that needs to be checked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4dad8914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(airline='Vistara', number_of_occurrences=127859)]\n",
      "The most represented airline seems to be Vistara, with 127859 occurrences.\n",
      "WARNING: Data is not processed yet, so this is just an assumption that needs to be checked\n"
     ]
    }
   ],
   "source": [
    "# Print the most represented airline\n",
    "# Initiate a SQL query in a string variable\n",
    "sql_query_2 = \"SELECT \" \\\n",
    "\"                   airline,\" \\\n",
    "\"                   COUNT(*) AS number_of_occurrences\" \\\n",
    "\"              FROM\" \\\n",
    "\"                   flights\" \\\n",
    "\"              GROUP BY \" \\\n",
    "\"                   airline\" \\\n",
    "\"              ORDER BY \" \\\n",
    "\"                   number_of_occurrences DESC\" \\\n",
    "\"               LIMIT \" \\\n",
    "\"                   1\"\n",
    "\n",
    "# Execute the query using Spark SQL and put into a list\n",
    "output_2 = spark.sql(\n",
    "    sql_query_2\n",
    ").collect() \n",
    "\n",
    "print(output_2)\n",
    "\n",
    "# Vistara seems to be the most represented airline, with 127,589 occurrences\n",
    "# WARNING: Data is not processed yet, so this is just an assumption that needs to be checked\n",
    "\n",
    "print(f\"The most represented airline seems to be {output_2[0][0]}, with {output_2[0][1]} occurrences.\")\n",
    "print(\"WARNING: Data is not processed yet, so this is just an assumption that needs to be checked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8fbcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-training (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
